---
title: "Online Supporting Information"
subtitle: "Assessing the Population-level Conservation Effects of Marine Protected Areas"
output: 
  bookdown::pdf_document2:
    keep_tex: true
  pdf_document: default
bibliography: references.bib
header-includes:
    - \usepackage{longtable}
    - \usepackage{booktabs}
    - \usepackage{eso-pic}
    - \usepackage{graphicx}
    - \usepackage[left]{lineno}
    - \usepackage{xcolor}
params:
  run_name: ["v6.0"]
  sim_years: [50]
  burn_years: [20]
  num_patches: [25]
always_allow_html: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, dpi = 600,
                      cache = FALSE, fig.width = 7, fig.asp = .75,
                      dev = "cairo_pdf")

```

```{r, include=FALSE}
library(sf)
library(ggmap)
library(viridis)
library(hrbrthemes)
library(scales)
library(patchwork)
library(rpart)
library(extrafont)
library(caret)
library(ggsci)
library(rEDM)
library(tidyverse)
library(ggtext)
library(rstan)
library(rstanarm)
library(bayesplot)
library(Synth)
library(here)

extrafont::loadfonts()
rstan_options(auto_write = TRUE)

functions <- list.files(here::here("functions"))

walk(functions, ~ here::here("functions", .x) %>% source()) # load local functions
save_plots <- TRUE

# sim_years <- 50
# 
# burn_years <- 20
# 
# num_patches <- 25

# run_name <- "v5.0"


width_1col <- 3.42 # inches

asp_1col <- 1.25

width_2col <- 7 # inches

asp_2col <-  .75

dpi <- 900

theme_1col <- hrbrthemes::theme_ipsum(base_size = 11,
                                      axis_title_size = 12)


theme_2col <- hrbrthemes::theme_ipsum(base_size = 12,
                                        axis_title_size = 14)

run_name <- params$run_name

sim_years <- params$sim_years

burn_years <- params$burn_years

num_patches <- params$num_patches

run_dir <- here::here("results", run_name)

experiment_dir <- here::here("results",run_name, "experiments")

load(file = here::here("results",run_name, "rawish_zissou_data.Rdata"))

load(file.path(run_dir, 'abundance_data.Rdata'))

model_runs <- read_rds( file.path(run_dir,"did_fits.rds"))

tmb_runs <- read_rds( file.path(run_dir,"tmb_model_fits.rds"))

# load(file = here::here("results",run_name, "model_runs.Rdata"))

processed_grid <-  read_rds(file.path(run_dir,"filtered_processed_grid.rds"))

load(file = file.path(run_dir ,"sim_grid.Rdata"))

load(file = file.path(run_dir,"plots.RData"))

valgrid <- read_rds(file.path(run_dir, "valgrid.rds"))


cdfw_catches <-
  read_csv(file = here::here("data", 'cdfw-catches.csv')) %>%
  group_by(sci_name, year) %>%
  summarise(catch = sum(pounds_caught, na.rm = T)) %>%
  left_join(
    life_history_data %>% select(taxa, classcode, commonname) %>% mutate(taxa = tolower(taxa)),
    by = c("sci_name" = "taxa")
  ) %>%
  filter(!is.na(classcode))



# cdfw_catches %>%
#   group_by(commonname, classcode, sci_name) %>%
#   summarise(catch =sum(catch, na.rm = TRUE)) %>%
#   mutate(in_analysis = classcode %in% unique(cip_data$classcode)) %>%
#   View()

density_ratios <- readRDS(file.path(run_dir,"density_ratios.rds"))

outcomes <- readRDS(file.path(run_dir,"outcomes.rds"))

outcomes <- outcomes %>% 
  filter(!is.na(mpa_effect))

density_ratios <- density_ratios %>% 
  filter(!is.na(biased_density_ratio))

   eqo <- outcomes %>%
     filter(year == max(year))


facet_labels <- c(
  mpa_size = "Range in MPA",
  depletion = "Depletion"
)




testplot <- ggplot()

panel_height = unit(1,"npc") - sum(ggplotGrob(testplot)[["heights"]][-3]) - unit(4,"line")

panel_width = unit(1,"npc") - sum(ggplotGrob(testplot)[["widths"]][-3]) - unit(4,"line")

gc <- guide_colorbar(frame.colour = "black",
                     ticks.colour = "white",
                     barheight = panel_height)


  hgc <- guide_colorbar(frame.colour = "black",
                       ticks.colour = "black",
                       barwidth = 10)

  
    wide_hgc <- guide_colorbar(frame.colour = "black",
                       ticks.colour = "black",
                       barwidth = 25)
    
theme_set(theme_1col)


# models_worked <- model_runs$tmb_fit %>% map("error") %>% map_lgl(is_null)

# model_runs <- model_runs %>%
#   filter(models_worked) %>%
#   mutate(tmb_fit = map(tmb_fit,"result")) %>%
#   mutate(processed_fits = map(tmb_fit, process_fits)) %>%
#   mutate(did_plot = map(processed_fits, "did_plot"))

base_run <- model_runs %>%
filter(var_names == "pisco_a", data_to_use == "all", center_scale == TRUE)

mpa_run <- model_runs %>%
  filter(data_source == "pisco",
         var_names == "pisco_a",
         data_to_use == "mpa_only")

fishsed_run <- model_runs %>%
  filter(data_source == "pisco",
         var_names == "pisco_a",
         data_to_use == "fished_only")

kfm_run <- model_runs %>%
  filter(data_source == "kfm")

used_data <- abundance_data$data[abundance_data$data_source == "pisco"][[1]]

filter_summary <- used_data %>% 
  select(classcode, targeted) %>% 
  unique() %>% 
  group_by(targeted) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(targeted = ifelse(targeted == 1,"yes","no")) %>% 
  spread(targeted, n)

did_data <- model_runs$did_fit[model_runs$data_source == "pisco" &
                                 model_runs$var_names == "pisco_a" &
                                 model_runs$data_to_use == "all"][[1]]$did_data


did_fit <- model_runs$did_fit[model_runs$data_source == "pisco" &
                                 model_runs$var_names == "pisco_a" &
                                 model_runs$data_to_use == "all"][[1]]$did_reg

did_results <- model_runs$did_fit[model_runs$data_source == "pisco" &
                                 model_runs$var_names == "pisco_a" &
                                 model_runs$data_to_use == "all"][[1]]$did_results


site_data <- read_csv(here::here("data",'Final_Site_Table_UCSB.csv')) %>%
  magrittr::set_colnames(., tolower(colnames(.))) %>%
  select(
    site,
    side,
    mpagroup,
    mpa_status,
    reserve,
    region,
    year_mpa,
    mpaareanm2,
    lat_wgs84,
    lon_wgs84
  ) %>%
  rename(lat_wgs84 = lon_wgs84,
         lon_wgs84 = lat_wgs84) %>%
  unique() %>%
  mutate(eventual_mpa = (year_mpa > 0))


top_species <- used_data$classcode %>% unique()

  
life_summaries <- life_history_data %>% 
  select(classcode, tm, vbgf.k, vbgf.linf) %>% 
  rename(age_mature = tm, vbk = vbgf.k, linf = vbgf.linf) %>% 
  unique() %>% 
  filter(classcode %in% top_species) %>% 
  select(-classcode) %>% 
  gather(variable,value) %>% 
  group_by(variable) %>% 
  summarise(min_val = min(value, na.rm = TRUE),
         max_val = max(value, na.rm = TRUE))

 sim_life_history <- sim_grid %>%
    mutate(
      age_mature = map_dbl(fish, "age_mature"),
      vbk = map_dbl(fish, "vbk"),
      linf = map_dbl(fish, "linf")
    ) %>%
    select(scientific_name, age_mature, vbk, linf) %>%
    unique() %>% 
   filter(age_mature > life_summaries$min_val[life_summaries$variable == "age_mature"],
          age_mature < life_summaries$max_val[life_summaries$variable == "age_mature"],
          vbk > life_summaries$min_val[life_summaries$variable == "vbk"],
          vbk < life_summaries$max_val[life_summaries$variable == "vbk"],
          linf > life_summaries$min_val[life_summaries$variable == "linf"],
          linf < life_summaries$max_val[life_summaries$variable == "linf"])
 
 year_bins <-
  seq(2003, max(pisco_data$year) + 1, by = 3)

 sim_mpa_effects <- outcomes %>% 
  filter(set == "ci",
         final_depletion > 0,
         f_v_m > .5) %>% 
  mutate(year = years_protected + 2002) %>% 
  filter(year <= max(pisco_data$year)) %>% 
  mutate(binned_year = cut(year, year_bins, include.lowest = FALSE))  %>% 
  filter(year >= 2003,
         !is.na(binned_year)) %>% 
  mutate(mpa_effect = pmin(mpa_effect,3))
 
 filter_summary <- used_data %>% 
  select(classcode, targeted) %>% 
  unique() %>% 
  group_by(targeted) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(targeted = ifelse(targeted == 1,"yes","no")) %>% 
  spread(targeted, n)

```

# (APPENDIX) Appendix {-} 

# Supporting Information (SI) 

## Computing environment

All code needed to reproduce our main results and manuscript can be found at https://github.com/DanOvando/population-effects-of-mpas. All analysis were performed in `r R.version.string`. Package versions are shown in Table.S\@ref(tab:pkg-info).

```{r pkg-info, results = "asis", eval=TRUE}
table <- devtools::package_info() %>% 
  select(package, loadedversion, date,source)

knitr::kable(table,
             digits = 2,
             caption = "Package versions and sources used in this paper",
             longtable = TRUE,
             booktabs = TRUE,
             format = "latex",
             col.names = colnames(table)) %>% 
  kableExtra::kable_styling(latex_options = c("hold_position", "repeat_header"))

```


## PISCO Data

All fish data used in the primary difference-in-difference model were collected by PISCO. The dive transect survey methods are described in @caselle2015, provided below for ease of reference

"Fish assemblages were surveyed annually as part of a long-term monitoring program conducted by the Partnership for Interdisciplinary Studies of Coastal Oceans (PISCO) using standard underwater visual belt survey methods (www.piscoweb.org). We analyzed data from 47 PISCO sites at the northern Channel Islands that were sampled annually from at least 2003 to 2012. We also excluded 3 sites on Anacapa where a much older MPA had already been established in 1978. MPAs on each island were sampled annually during June-October and we surveyed multiple sites inside and outside of any individual MPA. Details of MPA characteristics such as size and coastline extent are given in Hamilton et al. At each site, we conducted 8 to 12 fish transects that measured 30×2×2m at multiple levels in the water column: benthic, midwater, and kelp canopy (when present). Transects are laid out in a stratified random design, with multiple nonpermanent transects located in fixed strata (i.e., outer, middle, and inner edges of the reef). At each level in the water column, one SCUBA diver per transect counted and estimated the sizes of all fish to the nearest centimeter (total length), excluding small cryptic fishes"
- @caselle2015


We take a number of steps to translate the raw transect data into the total biomass densities used in this study. For the default run, we only include species that were observed at least once for at least 15 of the 18 years of available data. We also exclude "young of the year" observations due the challenges of correctly identifying and measuring these individuals. We omitted data from 1999 due to changes in the sampling procedures that occurred after 1999. Per recommendations from PISCO staff we omit observations from the canopy level of the transects (leaving the middle, bottom, and middle canopy levels). 

PISCO data report positive observations of fish, in the manner of number of individuals of a species seen within a particular size group. In order to use these data in our model we need to add in zeros for any transect that could have observed a given species of fish but did not. We assume that a fish could have been observed on a given transect if that species has ever been observed at that site in any time period in the data (PISCO data are organized by sites, with multiple transect at different locations within the borders of a site). If a species has never been observed at a site we assume that it does not occur at that site. 

Once zeros have been introduced to the database, we convert positive observations of fish from numbers to biomass. Each observation in the raw database lists the species, the number of individuals seen, and the size of those individuals (either as one value or as a minimum and maximum size for the group seen). PISCO staff compiled allometric information used to convert lengths to expected weights. For each observation then, we convert the observed lengths to weights per these relationships (accounting for variations in length types such as standard vs. total length). When minimum and maximum ranges were reported, we drew a number of samples equal to the number of observed fish in that group from a uniform distribution spanning the minimum and maximum reported size in that group. We assume all length-to-weight conversions are constant and deterministic. 

For each species at each transect, we calculate the biomass density of that transect as the sum of the observed biomass divided by the transect area. We then average the biomass densities for each species across all the transects at a given site, and lastly sum these mean species biomass densities to achieve the total mean species biomass at the site level. 

We include several additional sources of data in our regression analysis. Temperature readings are included from the PISCO data for each transect. We also include PISCO data on the estimated surge and visibility. We augmented these data with information on kelp cover over time from the Santa Barbara Channel Long Term Ecological Research Network [@lter2017]. We used a k-nearest neighbors algorithm to fill in missing kelp observations, and matched the interpolated kelp data to the PISCO data at the resolution of year-month-site (Fig.\@ref(fig:kelp-plot)). We include a variable capturing the mean cumulative number of observations across all observers conducting transects, in an effort to control for evolving observer skill. 

<!-- Temperature data were augmented with data from `FishLife` [@thorson2017c] to include the estimated preferred temperature for a given species, so that we can include deviations from the preferred temperature envelope as a predictor in the model. This allows different temperatures to have different effects on each species (and is less computationally intensive than estimating species-temperature slopes) (Fig.\@ref(fig:tempdev-plot)).  -->

We also included lagged catch totals in the Santa Barbara region for the commercially harvest species in the database, in an effort to control for changes in density caused by changes in fishing pressure. Catches were pulled from the CDFW website (https://www.wildlife.ca.gov/Fishing/Commercial/Landings), and extracted using the `tabulizer` package in R [@leeper2018] (Fig.\@ref(fig:catches-plot)). 

```{r catches-plot, fig.cap = "Total CDFW reported commercial catches in the Santa Barbara region"}

cdfw_catches %>% 
  group_by(classcode) %>% 
  mutate(nc = sum(catch > 0)) %>% 
  ungroup() %>% 
  filter(classcode %in% unique(used_data$classcode), nc > 13) %>% 
  ggplot(aes(year, catch)) + 
    geom_vline(aes(xintercept = 2003), linetype = 2, color = "red") +
  geom_line() + 
  facet_wrap(~commonname, scales = "free_y") + 
  theme_minimal() + 
  labs(x = "Year", y = "Catch (lbs)")

```


```{r kelp-plot, fig.cap="Mean kelp biomass by island over time from SBC LTER"}

used_data %>% 
  group_by(region,year) %>% 
  summarise(mean_kelp = mean(interp_kelp, na.rm = TRUE)) %>% 
  ggplot(aes(year, (mean_kelp), color = region)) + 
  geom_line() + 
  labs(x = "Year", y = "Mean Kelp Biomass")

```



```{r targ-trend-plot, fig.cap="Centered and scaled mean biomass densities of all targeted finfish in analysis before filtering"}

targeted_trend_plot <- pisco_data %>% 
  filter(targeted == 1) %>% 
  group_by(year, classcode, targeted, commonname) %>% 
  summarise(mean_biomass_density = mean(density_g_m2, na.rm = TRUE)) %>% 
  group_by(classcode) %>% 
  mutate(mean_biomass_density = scale(mean_biomass_density)) %>% 
  ggplot(aes(year,mean_biomass_density)) + 
  geom_hline(aes(yintercept = 0), linetype = 2) + 
  geom_vline(aes(xintercept = 2003), color = "red") +
  geom_line() + 
  facet_wrap(~commonname) +
  theme_minimal() + 
  theme(strip.text = element_text(size = 6),
        axis.text.x = element_text(size = 8)) + 
  labs(x = "Year", y = "Centered and Scaled Mean Biomass Density")

targeted_trend_plot
```

```{r nontarg-trend-plot, fig.cap="Centered and scaled mean biomass densities of all non-targeted finfish in analysis before filtering"}

nontargeted_trend_plot <- pisco_data %>% 
  filter(targeted == 0) %>% 
  group_by(year, classcode, targeted, commonname) %>% 
  summarise(mean_biomass_density = mean(density_g_m2, na.rm = TRUE)) %>% 
  group_by(classcode) %>% 
  mutate(mean_biomass_density = scale(mean_biomass_density)) %>% 
  ggplot(aes(year,mean_biomass_density)) + 
  geom_hline(aes(yintercept = 0), linetype = 2) + 
  geom_vline(aes(xintercept = 2003), color = "red") +
  geom_line() + 
  facet_wrap(~commonname) +
  theme_minimal() + 
  theme(strip.text = element_text(size = 6),
        axis.text.x = element_text(size = 8)) + 
  labs(x = "Year", y = "Centered and Scaled Mean Biomass Density")

nontargeted_trend_plot
```


```{r classcode, eval = FALSE}

species_data <- used_data %>% 
  select(classcode, commonname, taxa, targeted) %>% 
  unique() %>% 
  arrange(desc(targeted)) %>% 
  mutate(targeted = targeted == 1) %>% 
  rename(`Common Name` = commonname, 
         `Scientific Name` = taxa,
         `Targeted?` = targeted)

status <- read_csv(here::here("data","stock-status-summaries.csv")) %>% 
  select(classcode, `Stock Status`)

species_data <- species_data %>% 
  left_join(status, by = "classcode")

knitr::kable(species_data,
             digits = 2,
             caption = "Species included in estimation model",
             longtable = TRUE,
             booktabs = TRUE,
             col.names = colnames(species_data)) %>%
  kableExtra::kable_styling(latex_options = c("hold_position", "repeat_header"))


```



## Difference-in-Difference Model

The difference-in-difference (DiD) regression amounts to estimating the pre-post MPA difference in the biomass densities of targeted species minus the same difference for non-targeted species in the Channel Islands.

The simplified form of this model is

\begin{equation}
  d_{i} \sim Gamma(e^{\beta_0 + \beta_1T_{i} +  \beta_2MPA_{i} + \beta_{3}T_iMPA_i + \mathbf{B^cX_i} + \mathbf{B^sS_i}},shape, scale)
\label{eq:did}
\end{equation}


The full list of included coefficients and their estimated values can be seen in Table.\@ref(tab:did-coefs). 

To provide greater detail on this process, we first conduct the data pre-processing described earlier. From there, we aggregated data to the level of total mean biomass density of targeted and non-targeted species at each site each year. As such, our base model estimates the effect of the MPAs on total mean biomass density of targeted species, though we also explore the effect on alternative specifications such as mean biomass of targeted species. the model was then fit using the `rstanarm` package in R (5000 iterations, 2500 warmup, 4 chains, adapt_delta = 0.85). 

The intercept prior was was determined using the `rstanarm` `autoscale` function. For the non-intercept terms, we manually set a normal(0,2) prior. This implies that coefficients such as the MPA effect have a prior that provides support for an effect size centered on zero with a range of roughly -4 to 4. Since the covariates are centered and scaled, and the dependent variable is on the log-scale, this is an extremely diffuse prior (e.g. a one standard deviation change in an independent variable changes the dependent variable by 4 on the log scale). 

We weight each observation such that within MPA data are assigned a total weight of 0.2 and outside-MPA data a total weight of 0.8, in order to represent the proportion of the available habitat inside MPAs and outside. This makes the assumption that all areas throughout that Channel Islands are identical in terms of habitat / carrying capacity for the species in question. If detailed data on habitat are available, this method could be modified to weight each area by the available habitat in that area. See Fig.\@ref(fig:no-weight-plot) for a companion analysis without weighting (which implicitly assumes that the MPAs contain more of the available habitat than the outside-MPA areas, since the MPAs make up a disproportionate amount of the samples relative to their physcial area). 


The full table of covariates and their posterior means and 89% credible interval can be found in Table.S\@ref(tab:did-coefs). "var" refers to variable, "_2" indicates a squared term. tex is the mean cumulative number of observations of the observers collecting the raw data, surge is the mean reported surge across transects, kelp is the mean kelp coverage at the site, temp is the water temperature, regional_temp_dev is the water temperature at a given site scaled by the mean water temperature at that site. Targeted is a Boolean marker indicating whether the given observation is for targeted or non-targeted species. 

```{r did-coefs, results = "asis",eval = TRUE}
did_fit %>%
  broom::tidy(intervals = TRUE, prob = 0.89) %>%
  select(term, estimate, lower, upper) %>%
  rename(
    mean = estimate,
    lower_89th_ci = lower,
    upper_89th_ci = upper
  ) %>%
  knitr::kable(
    digits = 2,
    caption = "Posterior means and credible interval for key model coefficients",
    longtable = TRUE,
    booktabs = TRUE ) %>%
  kableExtra::kable_styling(latex_options = c("hold_position", "repeat_header"))

```

```{r prior-plot, fig.cap="Prior and posterior distributions of the estimated MPA effect over time"}

priors <- tibble(year = unique(did_results$year)) %>% 
  mutate(prior = list(rnorm(500,0,2))) %>% 
  unnest(cols = prior)

did_results %>% 
  filter(between(prank, 0.05, 0.95)) %>% 
  ggplot() + 
  geom_density(aes(did, fill = "Posterior", y = ..scaled..), color = "transparent", alpha = 0.75) + 
  geom_density(data = priors, aes(prior, fill = "prior", y = ..scaled..), color = "transparent",
               alpha = 0.5) +
  facet_wrap(~year) + 
  scale_fill_discrete(name = '') + 
  scale_y_continuous(name = "Scaled Density")
  


```

We include a series of standard visual diagnostic plot for Bayesian models below, with brief descriptions of the key outcome of the diagnostic included in the figure captions. The model had 0 divergences or max tree depth saturations. 


```{r, echo = FALSE}

rstan::check_hmc_diagnostics(did_fit$stanfit)

```


```{r rhat-plot, fig.cap="Histogram of potential scale reduction statistic Rhat. All values are below 1.05, indicating there is not evidence of chain convergence failure"}

data.frame(rhat = bayesplot::rhat(did_fit)) %>% 
             ggplot(aes(rhat)) + 
             geom_histogram() + 
             geom_vline(aes(xintercept = 1.05))

```


```{r energy-plot, fig.cap = "HMC energy diagnostic plots. Closely matching histograms shows there is no evidence of excessively fat tails"}

mcmc_nuts_energy(nuts_params(did_fit))

```


```{r}
y <- (did_fit$y)

yrep <- (rstanarm::posterior_predict(did_fit, draws = 500))
```

```{r, fig.cap = "Posterior Predictive distribution of total biomass density (blue lines) and observed distribution of total biomass density (red line)"}

ppc_dens_overlay(y = y,
                 yrep = yrep) +
  scale_x_continuous(name = "Total Biomass Density") +
  scale_colour_discrete(labels = c("Observed", "Posterior Predictive"),
                       name = '')

```



```{r mean_test_plot, fig.cap = "Posterior predictive mean (distribution) and empirical mean of total biomass density. Posterior predictive mean adequately covers empirical mean."}

ppc_stat(y,  yrep, stat = "mean") 
```




```{r sum_test_plot, fig.cap = "Posterior predictive sum (distribution) and empirical sum of total biomass density. Posterior predictive sum adequately covers empirical sum."}

ppc_stat(y,  yrep, stat = "sum") 
```


```{r sd_test_plot, fig.cap = "Posterior predictive standard deviation (distribution) and empirical standard deviation of total biomass density. Posterior predictive standard deviation adequately covers empirical standard deviation"}
ppc_stat(y,  yrep, stat = "sd") 

```



```{r min_test_plot, fig.cap = "Posterior predictive minimum (distribution) and empirical minimum of log total biomass density. Model slightly overpredicts minimum value in the data"}

ppc_stat(y,  yrep, stat = "min") 
```



```{r max_test_plot, fig.cap = "Posterior predictive maximum (distribution) and empirical maximum of total biomass density. Model underestimates true maximum of the data."}
ppc_stat(y,  yrep, stat = "max") 

```



```{r resid-plot,fig.cap = "Posterior predictive total biomass densities plotted against mean posterior predictive residuals" }
ppc_error_scatter_avg_vs_x(y, yrep, colMeans(yrep)) + 
  scale_x_continuous(name = "Predicted total biomass density") + 
  scale_y_continuous(name = "Mean Posterior Predictive Residuals") + 
  geom_hline(yintercept = 0)
```


```{r resid-hist-plot, fig.cap = "Histograms of residuals for targeted and non-targeted obesrvations."}

temp <- did_data %>% 
  mutate(targ = ifelse(targeted == 1, "Targeted","Non-Targeted"))
ppc_error_hist_grouped(y, yrep = yrep[1:2,], group = temp$targ) + 
  geom_vline(aes(xintercept = 0)) + 
  scale_x_continuous(name = "Residuals")
```


### Additional Difference-in-difference Runs

We include a variety of additional model runs designed to explore the sensitivity of our key results to various assumptions and data processing steps included in our base results. Description and key message are provided inside figure captions. 

Our base run uses data collected by PISCO. As a robustness check to our main results, we repeated our analysis utilizing data provided by the [Kelp Forest Monitoring Program (KFM)](https://science.nature.nps.gov/im/units/medn/monitor/kelpforest.cfm) conducted in the Channel Islands.


We include one run using only variables available in both datasets, to explore sensitivity of our results to selected covariates (Fig.\@ref(fig:kfm-data)). 

```{r kfm-data, fig.cap="Model fit to PISCO data but only using variables also available for KFM data", results="hide"}

val_runs <- model_runs %>% 
  mutate(did_results = map(did_fit,"did_results"))
  

ggplot() +
 tidybayes::stat_halfeye(
    data = val_runs$did_results[[2]],
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
  geom_hline(yintercept = 0)

```


We fit an alternative model using data from the KFM program to test whether a different dataset from the same region provides different results. KFM based results are qualitatively similar to those from PISCO data (Fig.\@ref(fig:kfm-fit))

```{r kfm-fit, fig.cap="Model fit to KFM data. Results are more uncertain than using PISCO data, but follow the same trend estimated from the PISCO data."}

ggplot() +
 tidybayes::stat_halfeye(
    data = val_runs$did_results[[3]],
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    geom_hline(yintercept = 0)


```


We ran a version of the model using data from only inside MPAs. This serves as a test of whether our results are being entirely driven by the outside-MPA data, and allows us to compare results from inside MPAs to those outside (Fig.\@ref(fig:mpa-fit-plot)). 

```{r mpa-fit-plot, fig.cap="Estimated MPA effects using PISCO data from inside MPAs only. The base model uses data from both inside and outside MPAs. These results show that the same general trend holds when only using data from inside the MPAs, though the model estimates greater probability of higher positive effects with only MPA data, compared to the model fit using all the data.",results = "hide"}

ggplot() +
 tidybayes::stat_halfeye(
    data = val_runs$did_results[[4]],
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
  geom_hline(yintercept = 0)

  

```


We ran a version of the model using data from only outside MPAs. This serves as a test of whether our results are being entirely driven by the inside-MPA data, and allows us to compare results from inside MPAs to those outside (Fig.\@ref(fig:fished-fit-plot)). 


```{r fished-fit-plot, fig.cap="Estimated MPA effects using PISCO data from outside MPAs only. The base model uses data from both inside and outside MPAs. These results show that the same general trend holds when only using data from outside the MPAs, though the model estimates less probability of high positive effects witout MPA data, compared to the model fit using all the data.",results = "hide"}

ggplot() +
 tidybayes::stat_halfeye(
    data = val_runs$did_results[[6]],
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    geom_hline(yintercept = 0)


```


We include a model run using nearly all observed species, to test whether our results are being influenced by omission of rarely observed species (Fig.\@ref(fig:no-filter-plot)). 

```{r no-filter-plot, fig.cap="The base model only includes consistently observed species of finfish. For this run, we include species that have been seen in at least two years (down from fifteen). The results remain essentially unchanged.",results = "hide"}
no_filter <- model_runs %>%
  slice(1) %>%
  left_join(abundance_data, by = "data_source") %>%
  mutate(
    did_fit = pmap(
      list(
        data = data,
        data_to_use = data_to_use,
        data_source = data_source
      ),
      estimate_did,
      min_classcode_years = 2,
      iter = 2500,
      site_data = site_data,
      cdfw_catches = cdfw_catches,
      life_history_data = life_history_data
    )
  )

ggplot() +
 tidybayes::stat_halfeye(
    data = no_filter$did_fit[[1]]$did_results,
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    geom_hline(yintercept = 0)


```


```{r no-weight-plot, fig.cap="Version of the model fit without reweighting samples in proportion to area",results = "hide"}
no_weight <- model_runs %>%
  slice(1) %>%
  left_join(abundance_data, by = "data_source") %>%
  mutate(
    did_fit = pmap(
      list(
        data = data,
        data_to_use = data_to_use,
        data_source = data_source
      ),
      estimate_did,
      iter = 2500,
      site_data = site_data,
      cdfw_catches = cdfw_catches,
      life_history_data = life_history_data,
      weight_samples = FALSE
    )
  )

ggplot() +
 tidybayes::stat_halfeye(
    data = no_weight$did_fit[[1]]$did_results,
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    geom_hline(yintercept = 0)


```

For ease of interpretation and model convergence, our default model estimates MPA effects in three-year bins. For this run we estimate the effect annually, relative to the year 2000. Results show the same overall trend and magnitude reported in our base model (Fig.\@ref(fig:no-bin-plot)). 

```{r no-bin-plot, fig.cap="For ease of interpretation and model convergence, our default model estimates MPA effects in three-year bins. For this run we estimate the effect annually, relative to the year 2000. Results show the same overall trend and magnitude reported in our base model.", results = "hide", eval = TRUE}
no_bin <- model_runs %>%
  slice(1) %>%
  left_join(abundance_data, by = "data_source") %>%
  mutate(
    did_fit = pmap(
      list(
        data = data,
        data_to_use = data_to_use,
        data_source = data_source
      ),
      estimate_did,
      iter = 2500,
      first_year = 2001,
      bin_width = 1,
      site_data = site_data,
      cdfw_catches = cdfw_catches,
      life_history_data = life_history_data
    )
  )

ggplot() +
 tidybayes::stat_halfeye(
    data = no_bin$did_fit[[1]]$did_results,
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    scale_x_discrete(guide = guide_axis(n.dodge = 2))

```


Our base run estimates the effect of MPAs on total biomass densities of targeted finfish. For this run, we instead estimate the effect on mean biomass densities of targeted species. Results show the same pattern as our base run (Fig.\@ref(fig:mean-fit)). 

```{r mean-fit, fig.cap="Our base run estimates the effect of MPAs on total biomass densities of targeted finfish. For this run, we instead estimate the effect on mean biomass densities of targeted species. Results show the same pattern as our base run.", results="hide"}
mean_fit <- model_runs %>%
  slice(1) %>%
  left_join(abundance_data, by = "data_source") %>%
  mutate(
    did_fit = pmap(
      list(
        data = data,
        data_to_use = data_to_use,
        data_source = data_source
      ),
      estimate_did,
      fit_mean = TRUE,
      iter = 2500,
      site_data = site_data,
      cdfw_catches = cdfw_catches,
      life_history_data = life_history_data,
      refresh = 1000
    )
  )

ggplot() +
 tidybayes::stat_halfeye(
    data = mean_fit$did_fit[[1]]$did_results,
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    scale_x_discrete(guide = guide_axis(n.dodge = 2))

```

Appropriately addressing the problem of "missing" observations is a critical challenge in any field observation study. If no observations of a given fish species were recorded on a given transect, should the density of that species on that transect be marked as zero, and influence the estimate of the overall mean density accordingly? The obvious answer seems to be yes, but what if that species simply does not live in the environment covered by a particular transect, or was not present during the particular time of the diver's observation? For our base runs, we assign a value of zero density on a given transect for any fish species that has been observed at least once at a given site at any time in our data but was not observed on that particular transect. If that species was never observed at that site, we do not include a zero for that species. Our rationale for this is that given the shifting nature of the sampled sites, and the intensity of sampling at those sites, we do not want to skew density trends by changes in the amount of suitable habitat for a given species sampled. However, this is clearly a strong assumption. For example, perhaps the decreasing trend in mean densities from 2000 to 2004 is due to increased number of sites (and therefore zeros) included in the data. To assess the potential importance of this choice, we can compare the mean densities of targeted and non-targeted species over time with the added zeros to the mean densities using only positive observations (i.e. not including any zeros in the data, (Fig.S\@ref(fig:no-zero-fit)). The trends in the raw densities, and most importantly the mean trends of targeted and non-targeted fishes, are nearly identical whether or not zeros are added, providing strong evidence that our choice of how to incorporate missing observations into the data are not strongly influencing our overall results.  
 
```{r no-zero-fit, fig.cap="Our base run estimates the effect of MPAs on total biomass densities of targeted finfish. For this run, we instead estimate the effect on mean biomass densities of targeted species. Results show the same pattern as our base run.", results = "hide"}


nozero_fit <- model_runs %>%
  slice(1) %>%
  left_join(abundance_data, by = "data_source")


nozero_fit$data[[1]] <- nozero_fit$data[[1]] %>% filter(any_seen == TRUE)

nozero_fit <-  nozero_fit%>%
  mutate(
    did_fit = pmap(
      list(
        data = data,
        data_to_use = data_to_use,
        data_source = data_source
      ),
      estimate_did,
      iter = 2500,
      site_data = site_data,
      cdfw_catches = cdfw_catches,
      life_history_data = life_history_data
    )
  )

ggplot() +
 tidybayes::stat_halfeye(
    data = nozero_fit$did_fit[[1]]$did_results,
    aes(year, did, color = "Empirical Estimate"),
    .width = c(0.5, 0.95),
    slab_alpha = 0.95  ) +
  scale_y_continuous(name = "MPA Effect") +
  scale_x_discrete(name = element_blank()) +
  theme(legend.position = "top") +
  scale_fill_brewer(name = "Simulation Quantiles") + 
  scale_color_manual(values = "red", name = '') + 
    scale_x_discrete(guide = guide_axis(n.dodge = 2))

```

### Synthetic controls

Synthetic controls are an alternative method for attempting to estimate the causal effect of a policy intervention [@abadie2010]. A difference-in-difference approach assumes that some observable group serves as an adequate control for the state of the treated group in an untreated world. In our default case, we assume that the mean standardized index of non-targeted species are our control for the targeted species. Alternatively, synthetic controls use timeseries of treated and non-treated groups before and after treatment to construct a new "control" group built by weighting the pre-treatment timeseries of un-treated observations (together with covariates) such that the synthetic control group matches the trends in the treated group pre-treatment. 


We chose to present difference-in-difference as our main result since it better allows us to capture the uncertainty in the data generating process through our hierarchical model. However, we felt that it was worth exploring whether synthetic controls provided substantially different results than our default model. 

For the first synthetic control, we pulled our standardized mean index of abundance for targeted species as a whole from our difference-in-difference model as our treated group. We then pull the standardized indices of abundance for each of the non-targeted groups from the difference-in-difference to use as the candidate untreated components for the synthetic controls. A complete synthetic control analysis would require more extensive validation of the methods, but we use this approach simply to explore whether we observe substantially divergent results in the synthetic control versus the difference-in-difference model. 

We centered and scaled the candidate abundance indices to facilitate model convergence given the very few number of pre-treatment years available. The results of a synthetic control model are presented as the difference between the observed treatment outcome and the synthetic control (the difference in this case being in units of standard deviations). The model was not able to construct an adequate synthetic control at this level, as shown by the differences between the treated group and the synthetic control pre-treatment. However, we would note that the post-treatment results do show similarities with our main results, namely a lack of a clear divergence between the treatment and the control, and an upwards trend up through the earl 2010s followed by a decline (Fig.S\@ref(fig:total-synth)). 


```{r, include = FALSE}

years <- unique(used_data$year)

life_history <- used_data %>%
  select(classcode) %>%
  unique() %>%
  mutate(numeric_classcode = as.numeric(as.factor(classcode)))


nontargeted_index <- data_frame(abundance_hat = fit_report$abundance_hat,
                               classcode = rep(1:n_distinct(used_data$classcode), each = length(years))) %>%
  mutate(log_abundance_hat = log(abundance_hat)) %>%
  group_by(classcode) %>%
  mutate(year =years) %>%
  mutate(scaled_abundance_hat = (abundance_hat - mean(abundance_hat)) / sd(abundance_hat)) %>%
  ungroup() %>%
  rename(numeric_classcode = classcode) %>%
  left_join(life_history, by = "numeric_classcode" ) %>% 
  left_join(unique(abundance_data$data[[1]] %>% select(classcode, targeted)), by = "classcode") %>% 
  filter(targeted == 0) %>% 
  select(log_abundance_hat, year, classcode, targeted)


targeted_index <- tmb_runs$tmb_fit[[1]]$zissou_estimates %>%
  filter(
    stringr::str_detect(variable, "(targeted_did_betas)"),!str_detect(variable, "non")
  ) %>%
  mutate(
    year = years,
    classcode = "targeted",
    targeted = 1
  ) %>%
  rename(log_abundance_hat = estimate) %>% 
  select(colnames(nontargeted_index))

  # filter(variable == "seeing_year_species_betas") %>%


nontargeted_covariates <- used_data %>% 
  select(classcode, contains("mean"),year, targeted) %>% 
  filter(targeted == 0) %>% 
  select(-mean_length) %>% 
  gather(variable, value, -classcode,-year,-targeted) %>% 
  group_by(classcode, variable, year) %>% 
  summarise(mean_value = mean(value, na.rm = TRUE)) %>% 
  spread(variable, mean_value)

targeted_covariates <- used_data %>% 
  select(classcode, contains("mean"),year, targeted) %>% 
  filter(targeted == 1) %>% 
  mutate(classcode = "targeted") %>% 
  select(-mean_length) %>% 
  gather(variable, value, -classcode,-year,-targeted) %>% 
  group_by(classcode, variable, year) %>% 
  summarise(mean_value = mean(value, na.rm = TRUE)) %>% 
  spread(variable, mean_value)


synth_covariates <- nontargeted_covariates %>% 
  bind_rows(targeted_covariates) 

synth_data <- targeted_index %>% 
  bind_rows(nontargeted_index) %>% 
  left_join(synth_covariates, by = c("classcode","year")) %>% 
    mutate(numeric_classcode = as.numeric(factor(classcode))) %>% 
  group_by(classcode) %>% 
  mutate(log_abundance_hat = scale(exp(log_abundance_hat))) %>% 
  ungroup() %>% 
  as.data.frame() %>% 
  select(-rolling_mean)


# synth_data %>%
#   group_by(classcode) %>%
#   mutate(index = (log_abundance_hat)) %>%
#   ggplot(aes(
#     year,
#     index,
#     color = factor(targeted),
#     group = interaction(targeted, classcode)
#   )) +
#   geom_line()

prepped_synth_data <-
  Synth::dataprep(
    foo = synth_data,
    predictors = colnames(synth_data)[str_detect(colnames(synth_data),"mean")],
    predictors.op = "mean",
    dependent = "log_abundance_hat",
    unit.variable = "numeric_classcode",
    unit.names.variable = "classcode",
    time.variable = "year",
    treatment.identifier = "targeted",
    controls.identifier = unique(synth_data$classcode)[unique(synth_data$classcode) != "targeted"],
    time.predictors.prior = years[years <= 2003],
    time.optimize.ssr = years[years <= 2003],
    time.plot = years
  )


synth_fit <- Synth::synth(prepped_synth_data)

gaps <-
  rownames_to_column(
    prepped_synth_data$Y1plot - (prepped_synth_data$Y0plot %*% synth_fit$solution.w) %>%
      as.data.frame()
  ) %>%
  rename(gap = w.weight,
         year = rowname) %>%
  mutate(year = as.numeric(year)) %>%
  mutate(synthetic = as.numeric(prepped_synth_data$Y0plot %*% synth_fit$solution.w)) %>% 
  mutate(treatment = gap + synthetic)

# path.plot(synth.res = synth_fit,
#           dataprep.res = prepped_synth_data
# ) 

total_gap_plot <- gaps %>% 
  ggplot(aes(year, gap)) + 
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_vline(aes(xintercept = 2003), color = "red")+
  geom_line() + 
    labs(x = "Year", y = "Standard deviations from synthetic control")


total_synth_plot <- gaps %>% 
  select(year, synthetic, treatment) %>% 
  gather(source, value, -year) %>% 
  group_by(source) %>% 
  # mutate(value = scale(value)) %>% 
  ggplot(aes(year, value, color = source, linetype = source)) + 
  geom_vline(aes(xintercept = 2003), color = "red")+
  geom_line() + 
    labs(x = "Year", y = "Standard deviations from synthetic control")

```


```{r  total-synth, fig.cap = "Difference in centered and scaled standardized targeted abundance and synthetic standardized targeted abundance"}
total_gap_plot
```

```{r raw-synth, include = FALSE, eval = FALSE}

  consistent_classcodes <- used_data %>%
      group_by(classcode, region) %>%
      filter(any_seen) %>%
      summarise(n_years = n_distinct(year)) %>%
      ungroup() %>%
      filter(n_years == n_distinct(used_data$year))
    

synth_data <- used_data %>% 
  filter(classcode %in% consistent_classcodes$classcode,
         region %in% consistent_classcodes$region) %>% 
  mutate(classcode = ifelse(targeted == 1, "targeted", classcode),
         region = ifelse(targeted == 1, "targeted", region)) %>% 
      group_by(year,
               site_side,
               region,
               zone,
               transect,
               eventual_mpa,
               classcode,
               targeted) %>%
      summarise(
        total_classcode_density = sum(exp(log_density)),
        var_tex = sum(cumulative_n_obs),
        var_vis = mean(mean_vis),
        var_temp = mean(mean_temp),
        var_depth = mean(mean_depth),
        var_surge = mean(surge),
        var_kelp = mean(interp_kelp)
      ) %>%  # sum density across all levels of a transect
      group_by(year, site_side, region, eventual_mpa, classcode, targeted) %>%
      summarise(
        md = mean(total_classcode_density),
        var_tex = mean(var_tex),
        var_vis = mean(var_vis),
        var_temp = mean(var_temp),
        var_depth = mean(var_depth),
        var_surge = mean(var_surge),
        var_kelp = mean(var_kelp)
      ) %>% # calculate mean density per year site, side, species, averaging over zone, transect
      ungroup() 

 synth_data <- synth_data %>% 
     group_by(year,region,classcode,targeted) %>%
      summarise(
        total_biomass_density = (sum(md) / 1e6) * 10000,
        # calculate total and mean biomass densities across all species per year site side
        mean_biomass_density = log((mean(md) / 1e6) * 10000 + 1e-3),
        var_tex = mean(var_tex),
        var_vis = mean(var_vis),
        var_temp = mean(var_temp),
        var_kelp = mean(var_kelp)
      ) %>%
   ungroup() %>% 
   mutate(classcode = ifelse(targeted == 1, classcode, paste(classcode, region, sep = '_'))) %>% 
      mutate(numeric_classcode = as.numeric(factor(classcode))) %>% 
   as.data.frame()
    
prepped_synth_data <-
  Synth::dataprep(
    foo = synth_data,
    predictors = colnames(synth_data)[str_detect(colnames(synth_data),"var")],
    predictors.op = "mean",
    dependent = "mean_biomass_density",
    unit.variable = "numeric_classcode",
    unit.names.variable = "classcode",
    time.variable = "year",
    treatment.identifier = "targeted",
    controls.identifier = unique(synth_data$classcode[synth_data$targeted == 0]),
    time.predictors.prior = years[years <= 2003],
    time.optimize.ssr = years[years <= 2003],
    time.plot = years
  )


synth_fit <- Synth::synth(prepped_synth_data)

gaps <-
  rownames_to_column(
    prepped_synth_data$Y1plot - (prepped_synth_data$Y0plot %*% synth_fit$solution.w) %>%
      as.data.frame()
  ) %>%
  rename(gap = w.weight,
         year = rowname) %>%
  mutate(year = as.numeric(year)) %>%
  mutate(synthetic = as.numeric(prepped_synth_data$Y0plot %*% synth_fit$solution.w)) %>% 
  mutate(treatment = gap + synthetic)

# path.plot(synth.res = synth_fit,
#           dataprep.res = prepped_synth_data
# ) 

total_gap_plot <- gaps %>% 
  ggplot(aes(year, gap)) + 
  # geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_vline(aes(xintercept = 2003), color = "red")+
  geom_line() + 
    labs(x = "Year", y = "Standard deviations from synthetic control")


total_synth_plot <- gaps %>% 
  select(year, synthetic, treatment) %>% 
  gather(source, value, -year) %>% 
  group_by(source) %>% 
  # mutate(value = scale(value)) %>% 
  ggplot(aes(year, value, color = source, linetype = source)) + 
  geom_vline(aes(xintercept = 2003), color = "red")+
  geom_line() + 
    labs(x = "Year", y = "Standard deviations from synthetic control")

```




As an extension, we repeated this process, but now treating each targeted species individually as the treated group, and the non-targeted species as the non-targeted. This is intended to explore whether we see clearer signals for individual species than we do for the targeted class as a whole. 

Overall we see similarly unclear results as the aggregate targeted synthetic control (and our main results). The synthetic control was better constructed for some individual species, but not clearly for any one, and most species showed some evidence of the upward-then-downward trend seen throughout our results (Fig.S\@ref(fig:synth-classcode-fits)). 


```{r, include = FALSE}

synth_foo <-
  function(treated_classcode,
           synth_data,
           targeted_classcodes) {
    # treated_classcode <- targeted_classcodes[1]
    
    temp_synth_data <- synth_data %>%
      filter(classcode == treated_classcode |
               !(classcode %in% targeted_classcodes))
    
    prepped_synth_data <-
      Synth::dataprep(
        foo = temp_synth_data,
        predictors = colnames(temp_synth_data)[str_detect(colnames(temp_synth_data), "mean")],
        predictors.op = "mean",
        dependent = "log_abundance_hat",
        unit.variable = "numeric_classcode",
        unit.names.variable = "classcode",
        time.variable = "year",
        treatment.identifier = treated_classcode,
        controls.identifier = unique(temp_synth_data$classcode)[unique(temp_synth_data$classcode) != treated_classcode],
        time.predictors.prior = c(2000:2003),
        time.optimize.ssr = c(2000:2003),
        time.plot = years
      )
    
    
    synth_fit <- Synth::synth(prepped_synth_data)
    
    gaps <-
      rownames_to_column(
        prepped_synth_data$Y1plot - (prepped_synth_data$Y0plot %*% synth_fit$solution.w) %>%
          as.data.frame()
      ) %>%
      rename(gap = w.weight,
             year = rowname) %>%
      mutate(year = as.numeric(year)) %>%
      mutate(synthetic = as.numeric(prepped_synth_data$Y0plot %*% synth_fit$solution.w)) %>%
      mutate(treatment = gap + synthetic)
  }

nontargeted_index <- data_frame(abundance_hat = fit_report$abundance_hat,
                               classcode = rep(1:n_distinct(used_data$classcode), each = length(years))) %>%
  mutate(log_abundance_hat = log(abundance_hat)) %>%
  group_by(classcode) %>%
  mutate(year = 1999 + 1:length(abundance_hat)) %>%
  mutate(scaled_abundance_hat = (abundance_hat - mean(abundance_hat)) / sd(abundance_hat)) %>%
  ungroup() %>%
  rename(numeric_classcode = classcode) %>%
  left_join(life_history, by = "numeric_classcode" ) %>% 
  left_join(unique(abundance_data$data[[1]] %>% select(classcode, targeted)), by = "classcode") %>% 
  select(log_abundance_hat, year, classcode, targeted)


synth_covariates <- pisco_data %>% 
  select(classcode, contains("mean"),year, targeted) %>% 
  select(-mean_length) %>% 
  gather(variable, value, -classcode,-year,-targeted) %>% 
  group_by(classcode, variable, year) %>% 
  summarise(mean_value = mean(value, na.rm = TRUE)) %>% 
  spread(variable, mean_value)


synth_data <- nontargeted_index %>% 
  left_join(synth_covariates, by = c("classcode","year")) %>% 
    mutate(numeric_classcode = as.numeric(factor(classcode))) %>% 
  group_by(classcode) %>% 
  mutate(log_abundance_hat = scale(exp(log_abundance_hat))) %>% 
  ungroup() %>% 
  as.data.frame()

targeted_classcodes <- unique(synth_data$classcode[synth_data$targeted == 1])

synth_classcode_fits <-
  tibble(targeted_classcodes = targeted_classcodes) %>%
  mutate(
    synthetic_fit = map(
      targeted_classcodes,
      synth_foo,
      synth_data = synth_data,
      targeted_classcodes = targeted_classcodes
    )
  )


synth_classcode_fits <- synth_classcode_fits %>% 
  unnest()

synth_classcode_fits_plot <- 
synth_classcode_fits %>% 
  ggplot(aes(year, gap)) + 
  geom_hline(aes(yintercept = 0), linetype = 2) +
  geom_vline(aes(xintercept = 2003), color = "red")+
  geom_line() + 
  facet_wrap(~targeted_classcodes) + 
  labs(x = "Year", y = "Standard deviations from synthetic control")


```




```{r synth-classcode-fits, fig.cap="Synthetic control gaps for each targeted species"}
synth_classcode_fits_plot + 
  theme_minimal()
```




## Testing Model Assumptions

### Simulation testing

We state that a difference-in-difference model using targeted and non-targeted species is capable (conditional on assumptions) of estimating the causal effect of MPAs. We simulated MPA outcomes to test this claim. We first test our estimation strategy under idealized circumstances, where recruitment is deterministic and PISCO divers all have constant and perfect observer skills. We simulate five species that vary only in their maximum size and length at maturity. For each of these species, we set one version that is targeted by fishing and one that is not. We set a constant fishing mortality rate for each simulated targeted species, and then ran two matched simulations, one with MPAs and one without. We then have our simulated divers sample data from each of these scenarios, and then pass the sampled biomass densities to a simplified version of our difference-in-difference model (omitting the probability of detection step). We can then compare the difference-in-difference estimates of the MPA effect to the true simulated effect. The difference in difference model is able to capture the simulated MPA effect under these circumstances (Fig.S\@ref(fig:simple-did-test))


```{r simple-did-test, fig.cap = "Simulated mean (red dashed line) and individual species (solid lines) MPA effects over time, along with difference-in-difference estimated MPA effects (mean with 95% confidence intervals)"}

load(file = file.path(run_dir,'simulated_did.Rdata'))

simple_performance$mixed_effect_did + 
  labs(title = '', x = "Years with MPA protection",
       y = "MPA Effect")
```


We then simulated a more complex example. We use the actual targeted and non-targeted species from our model. We assign species predominately seen in the western Channel Islands as "cold water" and those in the eastern Channel Islands as "warm water". We allow for stochasticity in recruitment. We use El Niño data as a simulated environmental recruitment driver, where we assume that El Niño events produce negative recruitment shocks for cold water species and *vice versa* for warm water species. We simulate three different divers each with different base skill levels, visual selectivities, and an evolving skill rate (such that observers get better over time). We hold fishing mortality rates constant for each species, although that fishing mortality affects each species differently because of intrinsic biological differences in maturity-at-age and steepness. We then test the ability of the difference-in-difference model to isolate the mean MPA effect across all of these targeted species, which our results show it is capable of doing (Fig.S\@ref(fig:complex-did-test)).

```{r complex-did-test,  fig.cap = "Simulated mean (red dashed line) and individual species (solid lines) MPA effects over time, along with difference-in-difference estimated MPA effects (mean with 95% confidence intervals)"}

pisco_performance$mixed_effect_did + 
    labs(title = '', x = "Years with MPA protection",
       y = "MPA Effect")

```

### Testing SUTVA with Convergent Cross Mapping

The difference-in-difference model also assumes that the targeted and non-targeted fishes do not directly or indirectly affect each other.This assumption is clearly violated on some level: all the fishes in this analysis are part of the same ecosystem and therefore interact to some degree. For example, if the protection of targeted predatory fishes results in increased mortality of non-targeted fishes, the model would attribute that as an increased population effect (greater divergence between the abundance of targeted and non-targeted species). Given the time scale of analysis (15 years of protection), we do not feel that massive trophic cascades are likely to have developed yet, given both the pace and complexity of trophic cascade development [@babcock2010; @pershing2015a]. A complete assessment of evidence for trophic cascades in the Channel Islands is beyond the scope of this study, but to address this question somewhat we utilized convergent cross mapping *sensu* @sugihara2012 to test for a significant causal signal between different broad trophic groups in the data, implemented in the `rEDM` package in R. 

Convergent cross mapping is a nonlinear forecasting method that uses observed time series data to test for significant causal links between variables. Following methods laid out in @clark2015 and @sugihara2012, we pool the abundance of each broad trophic group by region (Fig.S\@ref(fig:trophic-plot). This uses the data from the islands as "replicates", requiring the assumption that the islands are all part of the same dynamic system, but allowing us to take advantage of the extra information provided by each island to further resolve the reconstructed manifolds. Using these aggregations, we then test whether the variables can be properly embedded, i.e., if they have predictable manifold dynamics. We do this through a simplex forecasting test, using an individual timeseries' own lags to build a manifold. For each timeseries, the "best embedding dimension" is an approximation of the dimensionality of the dynamic system, in other words, the number of dimensions that define and predict the evolving states of the timeseries. This analysis shows that only the carnivore, piscivore, and planktivores groups show evidence of significant predictability (that is, that past dynamics of these species groups can predict future dynamics, Fig.S\@ref(fig:embed-plot)). 

```{r trophic-plot, fig.cap="Centered and scaled densities by broad trophic group and island over time"}
cip_data <- used_data
trophic_groups <- used_data %>% 
  select(classcode, broadtrophic) %>% 
  unique()


# dat <- abundance_trends %>%
#   left_join(trophic_groups, by = "classcode") %>%
#   group_by(broadtrophic, year) %>%
#   summarise(density = mean(scaled_abundance_hat)) %>%
#   group_by(broadtrophic) %>%
#   mutate(density = scale(density)) %>%
#   ungroup() %>% 
#   spread(broadtrophic, density) %>% 
#   arrange(year) %>% 
#   mutate(lag4_carnivore = lag(carnivore,4),
#          lag4_piscovore = lag(piscivore,4)) %>% 
#   na.omit() %>% 
#   ungroup() %>% 
#   filter(year > 1999) 
# dat %>%
#   ggplot(aes(year, density, color = broadtrophic)) +
#   geom_line()

dat <- cip_data %>%
  group_by(broadtrophic, region, site, side, transect, year, eventual_mpa) %>%
  summarise(density = sum(density_g_m2)) %>%
  group_by(broadtrophic, region, site, year) %>%
  summarise(mean_density = mean(density, na.rm = T)) %>%
  group_by(broadtrophic,region, year) %>%
  summarise(regional_density = mean(mean_density, na.rm = T)) %>% 
  ungroup() %>% 
  spread(broadtrophic, regional_density) %>% 
  group_by(region) %>% 
  arrange(year) %>% 
  mutate(lag4_carnivore = lag(carnivore,4),
         lag4_piscovore = lag(piscivore,4)) %>% 
  na.omit() %>% 
  ungroup() %>% 
  filter(year > 1999) 

 dat <- dat %>%
  select(-lag4_carnivore,-lag4_piscovore)%>%
  group_by(region)%>%
  mutate_at(vars(carnivore:planktivore),funs(norm=(.-mean(.))/sd(.)))->dat

group_trends_plot <- dat %>%
  select(region,year,contains("norm"))%>%
  gather("group","density",-region,-year)%>%
  ggplot(aes(year,density,col=group))+
  geom_line()+
  geom_point() +
  scale_color_locuszoom(name="Trophic Group",labels=c("carnivore","herbivore","piscivore","planktivore"))+
  labs(x="year",y="Centered and Scaled Density")+
  facet_wrap(~region)

group_trends_plot
```



```{r embed-plot, fig.cap = "Predictive skill as a function of embedding dimensions"}

## split data by region to analyze timeseries from each island separately
ana.dat <- dat %>% filter(region=="ANA")
sci.dat <- dat %>% filter(region=="SCI")
smi.dat <- dat %>% filter(region=="SMI")
sri.dat <- dat %>% filter(region=="SRI")

datnest <- dat %>% group_by(region) %>% nest()

datnorm <- dat %>% select(region,year,contains('norm')) %>% ungroup()

# have to record the segments corresponding to each "replicate" so simplex algorithm does not try to make predictions crossing time barriers
segs <- datnorm %>% mutate(ind=row_number()) %>% group_by(region) %>% summarise(first=first(ind),last=last(ind)) %>%
  select(-region)

var_names <- c("carnivore_norm","herbivore_norm","piscivore_norm","planktivore_norm")


regions.combined.simp.list <- map(var_names,function(x){
  temp <- datnorm %>% ungroup() %>% select(matches(x)) %>% as.data.frame()
  out <- simplex(as.numeric(temp[,1]),E=1:10,lib=as.matrix(segs),silent=T) %>%
    mutate(trophic=str_replace(x,"_norm",""))
  out
})


embed_plot <- bind_rows(regions.combined.simp.list) %>%
  ggplot(aes(E,rho,color=trophic))+
  geom_line(size=2)+
  facet_wrap(~trophic,nrow=2,scales="free_y")+
  geom_hline(yintercept = 0,color="black")+
  labs(x="Embedding Dimension (E)",y=expression(paste("Predictive Skill, ",rho)))+
  scale_x_continuous(breaks=seq(0,12,by=2))+
  scale_color_locuszoom()+
  guides(color=F)

embed_plot

```

Focusing on just these three groups then (removing herbivores), we can test for causal relationships between groups using convergent cross mapping and the logic of Takens' theorem of dynamic systems. Generalizations of Takens' theorem indicate that if two variables (in our case, species or physical variables) are part of the same dynamic system, their individual dynamics should reflect their relative causal influence [@sugihara2012]. In other words, if one variable is causally forced by another, that forcing should leave a signature on the first time series. Convergent cross mapping (CCM) tests for causation by using the attractor/manifold built from the time series of one variable to predict another (hence the "cross-mapping"). In simple terms, the *causal effect of A on B is determined by how well B cross-maps A*.

There are two criteria for CCM to establish causality:  First, and most obviously, predictive cross-map skill using all available data should be significantly greater than zero. Second, that predictability should be convergent.  Convergence means that cross-mapped estimates improve with library length (the number of state-space vectors used to build the attractor), because the attractor is more fully resolved and therefore estimation error should decline. Convergence is key to distinguishing causation from simple or spurious correlation. If two variables are spuriously correlated and not causally linked, CCM should fail to satisfy this second criterion. Based on these criteria, there is little evidence of significant dynamic interactions between trophic groups (Fig.S\@ref(fig:cross-map-cp)-\@ref(fig:cross-map-pis)). Cross-mapping produced positive predictive skill, but was non-convergent for all cross-mappings with the exception of carnivores cross-mapping planktivores (providing some evidence that planktivore dynamics may be a driver of carnivore dynamics). This analysis provides evidence that trophic cascades are unlikely to be a significant driver of our results. It is important to note though that this analysis does not mean that trophic cascades could not emerge in this system, rather that we do not detect them with these data at this time. 

```{r cross-map-fxn}
# plots a cross mapping between two variables in the data, given their variable names (grp), their optimal embedding dimensions (from simplex forecasting), and their preferred names for plotting
xmap <- function(grp1,grp2,E1,E2,name1,name2){
    # cross-map group 1 to group 2
  
  ccm1 <- ccm(datnorm,lib=as.matrix(segs),pred=as.matrix(segs),E=E1,lib_column= grp1,target_column = grp2,lib_sizes = c(10,25,50,75),num_samples=100,replace=T,silent=T,RNGseed = 41389)
  
  # test for convergence (is predictability at max library size significantly greater than at minimum library size?)

  rhomeans1 <- ccm1 %>% ccm_means()
  
  conv_test1 <- t.test(ccm1$rho[ccm1$lib_size==10],ccm1$rho[ccm1$lib_size==75])$p.value
  if((rhomeans1$rho[rhomeans1$lib_size==75]-rhomeans1$rho[rhomeans1$lib_size==10])<0.05) conv_test1 <- 1
  conv_test1 <- ifelse(conv_test1<0.05,"Convergent","Non-convergent")
  
  xmap1 <- ccm1 %>%
    group_by(lib_size)%>%
    summarise(rhomean=mean(rho,na.rm=T),upper=quantile(rho, 0.975),lower=quantile(rho, 0.025))%>%
    ungroup()%>%
    ggplot(aes(lib_size,rhomean))+
    geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3,fill="red")+
    geom_line(color="darkorchid3")+
    geom_hline(aes(yintercept = 0), linetype = 2) +
    labs(x="Library Size",y=expression(paste(rho, " (predictive skill)")),title=paste0(name1," xmap ",name2,"\n","(",conv_test1,")"))+
    theme(plot.title = element_text(size=6))
  
  # cross map group 2 to group 1
  # inspect the output of simplex from the previous step and use the best embedding dimension (highest rho) for the carnivore time series
  
  ccm2 <- ccm(datnorm,lib=as.matrix(segs),pred=as.matrix(segs),E=E2,lib_column= grp2,target_column = grp1,lib_sizes = c(10,25,50,75),num_samples=100,replace=T,silent=T,RNGseed = 41389)
  
  rhomeans2 <- ccm2 %>% ccm_means()
  
  conv_test2 <- t.test(ccm2$rho[ccm2$lib_size==10],ccm2$rho[ccm2$lib_size==75])$p.value
  if((rhomeans2$rho[rhomeans2$lib_size==75]-rhomeans2$rho[rhomeans2$lib_size==10])<0.05) conv_test2 <- 1
  conv_test2 <- ifelse(conv_test2<0.05,"Convergent","Non-convergent")
  
  xmap2 <- ccm2 %>%
    group_by(lib_size)%>%
    summarise(rhomean=mean(rho,na.rm=T),upper=quantile(rho, 0.975),lower=quantile(rho, 0.025))%>%
    ungroup()%>%
    ggplot(aes(lib_size,rhomean))+
    geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3,fill="red")+
    geom_line(color="darkorchid3")+
    geom_hline(aes(yintercept = 0), linetype = 2) +
    labs(x="Library Size",y=expression(paste(rho, " (predictive skill)")),title=paste0(name2," xmap ",name1,"\n","(",conv_test2,")"))+
    theme(plot.title = element_text(size=6))
  
  cross_map_plot <- xmap1 + xmap2

cross_map_plot
}
```



```{r cross-map-cp, fig.cap = "Cross mapping of effect of piscivores on carnivores (A) and carnivores on piscivores (B) in the PISCO data from 2000 to 2017. Shaded region show 95% confidence interval"}

car_pis<-xmap(grp1="carnivore_norm",grp2="piscivore_norm",E1=4,E2=4,name1="Carnivores",name2="Piscivores")
car_pl <- xmap(grp1="carnivore_norm",grp2="planktivore_norm",E1=4,E2=4,name1="Carnivores",name2="Planktivores")
pl_pis <- xmap(grp1="planktivore_norm",grp2="piscivore_norm",E1=4,E2=4,name1="Planktivores",name2="Piscivores")

car_pis
```


```{r cross-map-pl, fig.cap = "Cross mapping of effect of planktivores on carnivores (A) and carnivores on planktivores (B) in the PISCO data from 2000 to 2017. Shaded region show 95% confidence interval"}

car_pl

```

```{r cross-map-pis, fig.cap = "Cross mapping of effect of piscivores on carnivores (A) and carnivores on planktivores (B) in the PISCO data from 2000 to 2017. Shaded region show 95% confidence interval"}

 pl_pis 
```


```{r trophic-cor-plot, fig.cap="Estimated correlation coefficients between broad trophic groups at the island by year resolution", eval = FALSE}

trophic_effects_plot <- cip_data %>%
  group_by(broadtrophic, region, site, side, transect, year, eventual_mpa) %>%
  summarise(density = sum(density_g_m2)) %>%
  group_by(broadtrophic, region, site, year) %>%
  summarise(mean_density = mean(density, na.rm = T)) %>%
  group_by(broadtrophic,region, year) %>%
  summarise(regional_density = mean(mean_density, na.rm = T)) %>% 
  ungroup() %>% 
  spread(broadtrophic, regional_density) %>% 
  group_by(region) %>% 
  arrange(year) %>% 
  mutate(lag4_carnivore = lag(carnivore,4),
         lag4_piscovore = lag(piscivore,4)) %>% 
  na.omit() %>% 
  ungroup() %>% 
  filter(year > 1999) %>% 
  select(-year,-region) %>% 
  corrr::correlate() %>% 
   gather("colname","correlation",-rowname) %>% 
  ggplot(aes(rowname, colname,fill = correlation)) + 
  geom_tile() + 
  geom_text(aes(rowname, colname, label = round(correlation,2))) + 
  scale_fill_gradient2(low = "tomato", mid = "white", high = "steelblue", midpoint = 0, limits = c(-1,1),
                       guide = guide_colorbar(frame.colour = "black",barheight = 13)) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                   hjust = 1),
        axis.title.x = element_blank(),
        axis.title.y = element_blank()) 

trophic_effects_plot

```

## Operating Model

The model consists of 50 patches with wrapped edges (picture the waters around a circular island). For any one simulation we randomly pull a species and its associated life history from the `FishLife` [@thorson2017c] package in R. We pair these data with randomly selected values between 0.6 and 0.95 for Beverton-Holt steepness [as parameterized in @mace1994], as well as larval and adult dispersal rates. We randomly assign whether adult fish preferentially move towards patches with lower relative densities, as well as one of three potential types of recruitment density dependence [building off of @babcock2011]. Simulations are also assigned random fleet dynamics (open access ,constant effort, constant catch), responses to MPA (leave the fishery or concentrate outside MPAs), a fleet dispersal model (uniform in response to catch-per-unit-effort, in response to profit-per-unit-effort)

<!--   1. Local density dependence: Density dependence occurs independently in each patch, and recruits then disperse to nearby patches -->

<!--   2. Global density dependence: Density dependence is a function of the sum of spawning biomass across all patches, and recruits are then distributed according to habitat quality -->

<!--   3. Post-dispersal density dependence: Larvae are distributed throughout the system, and then density dependence occurs based on the density of adult biomass at the destination patch -->

<!-- We allow for three potential siting strategies for MPAs. In the first, MPAs are randomly placed. In the second, we assume that MPAs are placed in preferentially better habit (unfished recruitment is four times greater inside MPA locations). In the third, we allow for scenarios in which MPAs are placed in sources of larval dispersal. -->

<!-- Each simulation is randomly assigned a fleet model of the form  -->

<!--   1. Open access: fishing effort changes in response to profit-per-unit-effort -->

<!--   2. Constant effort: total fishing effort is constant over time (unless altered by MPA displacement model) -->

<!--   3. Constant catch: the fleet exerts as much effort as need to achieve a target catch -->

<!-- This fleet model is paired with a gear selectivity ranging from .1 to 1.5 of the length at 50% maturity for the species in question, and the fleet model is tuned to achieve a target fishing mortality relative to natural mortality ratio at equilibrium. -->

<!-- Along with the fleet dynamics model, each simulation is assigned a random fleet dispersal scenario: uniform dispersal (where the total effort of the fleet is divided evenly among all open patches), catch dispersal (where the total effort of the fleet is divided according to the catchable biomass in each available patch), and profit dispersal (where the total effort of the fleet is divided according to the profit per unit effort in each available patch). Fishing effort that occurred inside MPAs prior to closer can either leave the fishery, or be distributed to the patches outside the MPAs. -->

Each simulation is assigned an MPA scenario, defined by the number and size of MPAs, the placement of those MPAs, and the year that the MPAs are put in place. The population begins at unfished equilibrium and then fishing effort is applied in accordance to the fleet model. The MPAs are then placed during the randomly selected start year, allowing some runs to explore how the early dynamics of the MPA play out when the fishery and population they are placed on is not already at equilibrium. Each simulation is run to equilibrium with and without the selected MPA strategy (holding all else constant). We then measure the difference in biomass densities each time step in the scenario with and without the MPAs to calculate the population effect of the MPAs over time.



The operating model is a spatial single-species age-structured bio-economic model. The operating model itself is organized as an R package, which can be found and installed at https://github.com/DanOvando/spasm. Users can explore the functionality of the operating mode through an interactive web application at https://danovando.shinyapps.io/simmpa/. 


For the population model, numbers *n* at time *t* for age *a* are given by 

\begin{equation}
n_{t,a}=\begin{cases}
      = BH(ssb_{t-1}) & \text{if $a = 1$}\\
     = n_{t-1,a-1}e^{-(m + qE_{t-1}{\times}s_{a-1})}, & \text{if $1< a < max(age)$}\\
     =  n_{t-1,a}e^{-(m + qE_{t-1}{\times}s_a)} + n_{t-1,a-1}e^{-(m + qE_{t-1}{\times}s_{a-1})}, & \text{if $a = max(a)$}
  \end{cases}
  (\#eq:pop)
\end{equation}

where *BH* is the Beverton-Holt recruitment function, *ssb* is spawning-stock-biomass, *m* is natural mortality, *q* is catchability,*E* is fishing effort at time *t*, and *s* is selectivity at age *a*. 

Selectivity is modeled through a logistic form per

\begin{equation}
s_a=\frac{1}{(1 + e^{-log(19)\times\frac{l_a - l_{sel}}{\delta_{sel}}})}
  (\#eq:sel)
\end{equation}

where $l_a$ is the mean length at at age, $l_sel$ is the length at which on average 50\% of individuals are selected by the fishery, and $\delta_{sel}$ are the additional units of length at which on average 95\% of fish are selected by the fishery. 

*ssb* is calculated by converting age to mean length, calculating weight at age, maturity at age, and then calculating spawning stock biomass as the sum of spawning potential at age in a given time step. 

\begin{equation}
  l_{a} = l_{\infty}\left(1 - e^{-k(a - a_0)}\right)
  (\#eq:len)
\end{equation}



Weight at age is then given by 

\begin{equation}
  b_{a} = w_a \times l_{a}^{w_b}
  (\#eq:weight)
\end{equation}


and maturity *mat* is calculated as

\begin{equation}
  \frac{1}{(1 + e^{-log(19)\times\frac{l_a - l_{mat}}{\delta_{mat}}})}
  (\#eq:mat)
\end{equation}


where $l_{mat}$ is the length at which on average 50\% of individuals are sexual maturity, and $\delta_{mat}$ is the units of length beyond $l_{mat}$ at which on average 95\% of fish are sexually mature.

Spawning stock biomass at time *t* is then calculated as

\begin{equation}
  ssb_t = \sum_{a=1}^Aw_{a,t}mat_{a,t}n_{a,t}
    (\#eq:ssb)
\end{equation}


### Recruitment

Recruitment follows Beverton-Holt dynamics. We do however allow for three variants in the timing of density dependence:

  1. Local density dependence: Density dependence occurs independently in each patch, and recruits then disperse to nearby patches
  
\begin{equation}
  n_{t,a = 1,p} = \left(\frac{0.8{\times}r0_{p}\times{h}\times{ssb_{t-1,p}}}{0.2\times{ssb0_p}\times(1 - h)+(h - 0.2)\times{ssb_{t-1,p}}}\right)\times \boldsymbol{d^l} \times \epsilon_t
  (\#eq:dd1)
\end{equation}


where **d^l^** is the larval movement matrix, *h* is Beverton-Holt steepness (constrained between 0.6 and 0.99), *r0* is unfished recruitment, and *ssb0* is unfished spawning stock biomass.
  
  2. Global density dependence: Density dependence is a function of the sum of spawning biomass across all patches, and recruits are then distributed according to habitat quality

\begin{equation}
n_{t,a = 1,p} = \left(\frac{0.8{\times}\sum_{p=1}^P{r0_{p}}\times{h}\times\sum_{p=1}^P{ssb_{t-1,p}}}{0.2\times{\sum_{p=1}^Pssb0_p}\times(1 - h)+(h - 0.2)\times{\sum_{p=1}^Pssb_{t-1,p}}}\right)\times {hab_p} \times \epsilon_t
  (\#eq:dd2)
\end{equation}  
  

where *hab* is a vector of habitat quality by patch that sums to 1. 


3. Post-dispersal density dependence: Larvae are distributed throughout the system, and then density dependence occurs based on the density of adult biomass at the destination patch.


\begin{equation}
  larv_{t,p} = ssb_{t-1} \times\boldsymbol{d^l}
  (\#eq:larvmove)
\end{equation}


\begin{equation}
n_{t,a = 1,p} = \left(\frac{0.8{\times}r0_{p}\times{h}\times{larv_{t,p}}}{0.2\times{ssb0_p}\times(1 - h)+(h - 0.2)\times{larv_{t,p}}}\right) \times \epsilon_t
  (\#eq:dd3)
\end{equation}

$\epsilon$ represents multiplicative recruitment deviates. Deviates are calculated as


$$\epsilon_t = e^{recdev_t}$$  

`$recdev$ are the log-normal recruitment deviates in time *t*. 

The stochastic component of the deviate is 

$$\gamma_t \sim norm(-\sigma_r^2/2,\sigma_r)$$

and the final multiplicative recruitment deviate in time *t* is then

$$recdev_t = \gamma_t\sqrt{1 - ac_r^2} + recdev_{t-1}ac_r $$

where *ac* is the autocorrelation of the recruitment function (between 0 and 1). 

  
### Dispersal

Dispersal in the model is broken into two components: adult and larval. Both assume a Gaussian dispersal kernel of the form

\begin{equation}
m_{s,p_i,p_j}=\frac{1}{\sqrt{2\pi\sigma_{s,p_i}^2}}e^{-\frac{d_{p_i,p_j}^2}{2\sigma_{s,p_i}^2}}
  (\#eq:move)
\end{equation}


where *i* is the source patch, *j* is the destination patch, *d* is the distance between patches *i* and *j* (where distance is measured with wrapped edges, such that if there are 50 patches, patch 1 and patch 50 have a distance of 1), and $\sigma_s*$is the movement rate, in units of patches, for life stage *s* (adult or larval).

We allow the adult dispersal matrix to be affected by adult density dependence. The idea behind this is that adult fish will move more as densities increase, and become more sedentary as densities decrease (as habitat and food become more available for example). This allows us to simulate a scenario where as MPAs build up density they begin to export more adults to the surrounding waters, and if densities are lower in the fished areas these fish will actually become more sedentary. 

Under these conditions, the adult movement rate is a linear function of depletion (measured as $ssb/ssb_0$)

\begin{equation}
\sigma_{s=a,p}^* = max(slope\times{d _p+ \sigma_{s=a} \times dmod},0)
  (\#eq:ddmove1)
\end{equation}

where 

\begin{equation}
slope = \sigma_{s=a} - ( \sigma_{s=a} \times dmod)
  (\#eq:ddmove2)
\end{equation}


Under these conditions, when depletion *d = 1* (meaning the stock is unfished) the adult movement rate equals the max adult movement rate ($\sigma_{s=a}^* = \sigma_{s=a}$). When $d=0$ $\sigma_{s=a}^* = \sigma_{s=a} * dmod$. The greater *dmod* is then, the more movement rates from a patch decline as density declines.

We also allow for a "sprinkler" condition in which MPAs are placed in locations that disperse larvae to a much wider area than non-MPA locations. In this world, we simply multiply $\sigma_{s=l,p}$ by a sprinkler factor (by default 4) for any patch *p* that would eventually become an MPA (whether or not MPAs are ever introduced). In other words, when we compare two scenarios, one with MPA and one without, the "without" scenario still has higher larval movement rates in patches that become MPAs in the "with" scenario.

### Fleet Dynamics

We allow for three fleet models: constant effort, constant catch, and open-access. Constant effort means that total effort across all patches is equal in all time steps (unless MPAs force exit of effort as discussed below). Under constant catch, we set a target catch volume (in biomass, summed across all patches). Each time step, we calculate the fishing mortality rate that, given the fishable biomass in that time step, would produce the target catch. If there is insufficient fishable biomass available to support the target catch, we mark the population as crashed and stop the simulation (these crashed simulations are not included in the final analysis).

Under open-access, fishing effort expands in proportion to a weighted mean of profit-per-unit effort over the last *t* time steps.

\begin{equation}
profit_{t} = price\times{catch_t} - cost\times{E_t}^2
  (\#eq:profit)
\end{equation}


From there, we determine the new effort as 

\begin{equation}
E_t = E_{t-1} + \theta\times\sum_{i=t-1-l}^{t-1}w_i\frac{profit_{i}}{E^i}
  (\#eq:openaccess)
\end{equation}


where *w* is a weighting function which is just a linear function of time


\begin{equation}
  w_i = \frac{i}{\sum_{i=1}^li}
  (\#eq:oaweight)
\end{equation}

and *l* is the number of lagged time steps over which to calculate the weighted mean PPUE.

The open-access model can enter chaotic dynamics if the model parameters are not properly tuned. To address this, we first set price at 1, and set a $\theta$ such that when profits are about as large as they might conceivably be the fishery doubles in size. We then estimate reference points for the simulated fishery (Bmsy, Fmsy, MSY), and set a target bionomic equilibrium B/Bmsy. Holding the other parameters constant, we thing find a cost coefficient that produces the desired bionomic equilibrium. 

### Spatial Fleet Distribution

Given a total amount of effort, we then need to distribute that effort in space. In the simplest form, effort is evenly distributed throughout the available patches. 


\begin{equation}
E_{t,p} = E_t \times \frac{open_p}{\sum_{p=1}^Popen_p}
  (\#eq:simpleeffort)
\end{equation}



where *open* indicates whether patch *p* is open to fishing or not. 

Effort can also be distributed according to spawning stock biomass in fishable patches

\begin{equation}
E_{t,p} = E_t \times \frac{open_{t,p}ssb_{t,p}}{\sum_{p=1}^Popen_{t,p}ssb_{t,p}}
  (\#eq:biomasseffort)
\end{equation}


And lastly effort can be distributed according to profit-per-unit-effort


\begin{equation}
E_{t,p} = E_t \times \frac{open_{t,p}ppue_{t,p}}{\sum_{p=1}^Popen_{t,p}ppue_{t,p}}
  (\#eq:ppueeffort)
\end{equation}


Under the constant effort or open access scenarios, effort can immediately respond to MPA placement in one of two ways. Effort can concentrate outside the MPAs (such that the sum of effort before and after MPA placement stays constant), or effort can leave the MPAs, such that the total effort in the fishery is reduced by the amount of effort that occurred inside the MPAs immediately before MPA placement. This is intended to simulate a scenario where fishers that used to use the MPA simply leave the fishery rather than redistribute outside the MPA, due for example to costs or lack of location specific knowledge to fish outside the MPA.

### MPA Design

MPA design is relatively straightforward. We set a percentage of patches that are to be placed inside no-take MPAs. MPAs can either be placed continuously (e.g if there are 100 patches and 25% are in MPAs, patches 1 to 25 are in MPAs) or randomly. If the MPAs are placed randomly, we can also set a minimum MPA size. This controls the patchiness of the MPAs. As the "patchiness" factor approaches zero, the behavior equals that of random placement. As it approaches 1, the behavior approaches that of continuous placement. In between, the greater the patchiness, the more clustered together MPAs become.


## Simulations

We use this our operating model to simulate 10,000 different fisheries, where each fishery is a random combination of variables, described below

Table.S1 - Range of simulated variables

| Variable | Distribution|
|---------:|:-----------:|
| Scientific Name | Drawn from all possible species in `FishLife` (@thorson2017c)|
|steepness (h) | ~uniform(0.6,0.95)|
|Adult movement ($\sigma_{s=a}$) | ~uniform(0,0.25 * P)|
|Larval movement ($\sigma_{s=l}$) | ~uniform(0,0.25 * P)|
|Recruitment variation ($\sigma_{r}$) |  $\in\{0,0.05,.1,.2\}$|
|Recruitment autocorrelation ($ac_{r}$) |  $\in\{0,0.05,.1,.2\}$|
|DD adult movement (dmod) | $\in\{0.25,1\}$|
|Density-dependence timing | $\in\{local, global,post-dispersal\}$|
|\% Patches in MPA | ~uniform(0.01,1)|
|Initial fishing relative to natural mortality | ~uniform(0.01,4)|
|Selectivity as a multiple of maturity length| ~uniform(0.1,1.25)|
|Fleet model| $\in\{open-access, constant-effort,constant-catch\}$|
|Spatial effort model| $\in\{uniform, biomass,profits\}$|
|Years into simulation to start MPA| ~round(uniform(5,0.66 * T))|
|MPA is sprinkler?| $\in\{TRUE,FALSE\}$|
|Randomly place MPA?| $\in\{TRUE,FALSE\}$|
|Fleet reaction to MPA| $\in\{concentrate, abandon-ship\}$|
|Patchiness | ~uniform(0.01,0.75)|
|MPA habitat factor| $\in\{1, 4\}$|

One thing to note here is the random sampling of species' scientific names. The effect of MPAs, especially over the short term, will clearly be affected by factors such as the growth rate, the mortality rate, and the maturity schedule. These life history traits are related through a variety of biological processes, as such randomly sampling these parameters can lead to biologically nonsensical "frankenfish". We resolve this by using the `FishLife` package (@thorson2017c) instead. `FishLife` builds off of [FishBase](https://fishbase.org/), and provides estimate of key life history traits taking into account the relationships across these variables. For simulations then, we randomly pull a species from `FishLife`, and then pull the available life history information from that species for use in the operating model. This allows us to simulate a wide range of life history types in a realistic manner.

We ran 20,000 simulations from these distributions. Each simulation runs for 50 years in 50 patches (with a 25 year unfished burn-in period for conditions in which initial conditions cannot be solved analytically, for example when MPAs have better habitat than non-MPAs). For each simulation, we run one scenario without MPAs, though taking note of where the MPA would be as needed. For the second scenario, we hold everything constant except we now add in the MPAs as dictated by the particular simulation. 

##### Filtering Simulations

After the 20,000 simulations have run, we perform a series of filtering steps to remove runs that either a) produced chaotic dynamics during the open-access scenario; b) did not converge to the correct bionomic equilibrium in the open-access scenario; or c) crashed the population before the MPAs went into place (population falls below 5% of unfished biomass). These filtering steps left us with `r nrow(processed_grid) ` viable simulations. 


#### Additional Simulation Results

Simulation results are presented as percent differences in biomass densities with and without MPAs, in order to be comparable to the estimates that the regression model produces. However, this metric presents some problems as a measure of how "detectable" an effect size is. As depletion increases, relatively small changes in total biomass (relative to the variance in the observation process) can translate into large percent changes in biomass. For example, moving from a density of 0.02kg/m^2^ to 0.04kg/m^2^ translates to a 100% percent increase, but only a .02kg/m^2^ absolute increase, a small value to detect with a real observation program. 

To illustrate these, we present an alternative to our simulation results in which changes in biomass caused by MPAs is scaled by the unfished biomass in the system. 

```{r pop-conservation-effect, include = TRUE, fig.cap="Median (A) and range (B) of equilibrium population-level MPA conservation effects (change in total biomass with MPAs relative to without MPAs as a percentage of unfished biomass) across a range of depletion and MPA sizes (and incorporating the full range of scenarios included in our study). 'Range in MPA' is the percent of patches covered by an MPA, 'Depletion' is the depletion that would have occurred in equilibrium without the MPA"}


pop_time_plot <- outcomes %>%
  filter(years_protected > 0) %>%
  ggplot(aes(years_protected, pop_effect)) +
  geom_bin2d() +
  scale_fill_viridis(guide = gc)

ylabs <- c(expression(""<= "-50%"), paste0(seq(-25,75, by = 25),"%"),expression("">= "100%") )


ybreaks = seq(-.50,1, by = .25)

pop_depletion_plot <- outcomes %>%
  filter(year == max(year)) %>%
  ggplot() +
  geom_bin2d(aes(depletion, pop_effect), binwidth = c(.1, .1),
             show.legend = FALSE) +
  scale_fill_viridis(
  option = "A",
  # trans = "log10",
  guide = guide_colorbar(frame.colour = "black",
  frame.linewidth = 1,),
  name = "Median Effect"
  ) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), name = "Depletion") +
  scale_y_continuous(labels = ylabs, breaks = ybreaks, name = "") 


pop_depletion_plot <- outcomes %>%
    filter(year == max(year)) %>%
    mutate(
      rdep = cut(
        depletion,
        breaks = seq(0, 1, by = .2),
        labels = seq(0, .8, by = .2),
        include.lowest = TRUE
      )
      ,
      reff = cut(
        pop_effect,
        breaks = seq(-.6, 1, by = .2),
        labels = seq(-.6, .8, by = .2),
        include.lowest = TRUE
      )
    ) %>%
    group_by(rdep, reff) %>%
    count() %>%
    group_by(rdep) %>%
    mutate(pn = n / sum(n)) %>%
    ungroup() %>%
    mutate(rdep = as.numeric(as.character(rdep)),
           reff = as.numeric(as.character(reff))) %>%
    ggplot(aes(rdep, reff, fill = pn)) +
    geom_tile(show.legend = FALSE) +
    scale_fill_viridis(
      option = "A",
      # trans = "log10",
      guide = hgc,
      name = "% of Sims",
      labels = scales::percent_format(accuracy = 1)
    ) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1),
                       name = "Depletion",
                       expand = expand_scale(add = c(0,0))) +
    scale_y_continuous(labels = ylabs,
                       breaks = ybreaks,
                       name = "")

  pop_size_plot <- outcomes %>%
    filter(year == max(year)) %>%
    mutate(
      rsize = cut(
        mpa_size,
        breaks = seq(0, 1, by = .2),
        labels = seq(0, .8, by = .2)
      )
      ,
      reff = cut(
        pop_effect,
        breaks = seq(-.6, 1, by = .2),
        labels = seq(-.6, .8, by = .2)
      )
    ) %>%
    group_by(rsize, reff) %>%
    count() %>%
    group_by(rsize) %>%
    mutate(pn = n / sum(n)) %>%
    ungroup() %>%
    mutate(rsize = as.numeric(as.character(rsize)),
           reff = as.numeric(as.character(reff))) %>%
    ggplot(aes(rsize, reff, fill = pn)) +
    geom_tile() +
    scale_fill_viridis(
      option = "A",
      # trans = "log10",
      guide = hgc,
      name = "% of Sims",
      labels = scales::percent_format(accuracy = 1)
    ) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1),
                       name = "Range in MPA",
                       expand = expand_scale(add = c(0,0))) +
    scale_y_continuous(labels = ylabs,
                       breaks = ybreaks,
                       name = "Conservation Effect") +
    theme(legend.position = "top") +
    labs(title = 'B)')



 pop_facet_effect_plot <- outcomes %>%
  filter(year == max(year)) %>%
   select(pop_effect, mpa_size, depletion) %>%
   gather(measure, value, -pop_effect) %>%
   ggplot() +
   geom_bin2d(aes(value, pop_effect), binwidth = c(.1, .1), show.legend = TRUE) +
  scale_fill_viridis(
  option = "A",
  # trans = "log10",
  guide = hgc,
  name = "# of Sims"
  ) +
   facet_wrap(~measure, labeller = labeller(measure = facet_labels), strip.position = "bottom") +
   scale_x_percent(name = "", expand = c(0,0)) +
   scale_y_percent(name = "Pop. Conservation Effect", expand = c(0,0)) + 
   theme(legend.position = "top")


  pop_depletion_and_size_plot <- outcomes %>%
    filter(years_protected >= 0) %>%
    group_by(experiment) %>%
    mutate(depletion = plyr::round_any(depletion[years_protected == 0], .1),
           mpa_size = plyr::round_any(mpa_size, .1)) %>%
    filter(year == max(year)) %>%
    group_by(depletion, mpa_size) %>%
    summarise(median_mpa_effect = median(pop_effect, na.rm = TRUE)) %>%
    ggplot(aes(depletion, mpa_size, fill = median_mpa_effect)) +
    geom_tile() +
    # geom_contour(aes(z = median_mpa_effect, color = ..level..), show.legend = FALSE) +
    scale_fill_viridis(labels = scales::percent_format(accuracy = 1),
                       guide = hgc,
                       name = "Median Pop. Effect") +
  labs(x = "Depletion", y = "Range in MPA", title = "A)") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1),
                       expand = c(0,0)) +
    scale_x_continuous(labels = scales::percent_format(accuracy = 1), expand = c(0,0),
                       limits = c(0,1)) + 
    theme(legend.position = "top")
  
  # pop_depletion_and_size_plot <-  directlabels::direct.label(pop_depletion_and_size_plot, list("angled.boxes", box.alpha = 0.5))


  pop_combo_plot <-
    (pop_depletion_and_size_plot) + ((pop_size_plot) / pop_depletion_plot)  + plot_layout(widths = c(1.5, 1)) & theme(
    plot.margin = unit(c(0, 1, 0, 1), units = "lines"),
    axis.text.x = element_text(size = 8),
    legend.box.margin = unit(c(0, 0, 0, 0), units = "lines"),
    axis.text.y = element_text(size = 10)
    ) 
   
pop_combo_plot

```


<!-- ##### BACI -->

<!-- # ```{r baci-vs-mpa-effect-plot, include = FALSE, eval = FALSE} -->
<!-- #  -->
<!-- # baci_plot <- baci_outcomes %>% -->
<!-- #   filter(sprinkler == FALSE, mpa_habfactor == 1) %>% -->
<!-- #   # select(experiment, -->
<!-- #   #        years_protected, -->
<!-- #   #        mpa_effect, -->
<!-- #   #        adult_movement, -->
<!-- #   #        mpa_size, -->
<!-- #   #        contains("baci")) %>% -->
<!-- #   group_by(experiment) %>%  -->
<!-- #   mutate(b0 = unique(`no-mpa`[year == 1])) %>%  -->
<!-- #   ungroup() %>%  -->
<!-- #   mutate(mpa_effect = (`with-mpa` - `no-mpa`) / b0, -->
<!-- #          baci = baci / b0) %>%  -->
<!-- #   mutate(adult_movement = adult_movement / max(adult_movement)) %>% -->
<!-- #   group_by(experiment) %>%  -->
<!-- #   filter(years_protected == max(years_protected)) %>% -->
<!-- #   ggplot(aes(y = (mpa_effect), x = (baci / b0))) + -->
<!-- #     # geom_hline(aes(yintercept = 0)) +  -->
<!-- #   # geom_vline(aes(xintercept = 0)) +  -->
<!-- #   geom_smooth(method = "lm", se = FALSE) + -->
<!-- #   # geom_abline(aes(slope = 1, intercept = 0), linetype = 2, size = 1.5, color = "red") + -->
<!-- #   geom_point(aes(color = adult_movement, size = mpa_size), alpha = 0.5, show.legend = FALSE)  + -->
<!-- #   # labs(y = "True % Increase in Biomass", x = "% BACI") + -->
<!-- #   scale_color_viridis(guide = wide_hgc, labels = scales::percent_format(accuracy = 1), name = "Fish Movement", -->
<!-- #                       option = "cividis") +  -->
<!-- #   theme(legend.position = "top") -->
<!-- #  -->
<!-- # pdf(file =  "figs/baci.pdf",width = 8, height = 5, useDingbats = TRUE) -->
<!-- # print(baci_plot) -->
<!-- # dev.off() -->
<!-- #  -->


## References


